{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTJXgWy5SjFuP4TlR9MS8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdullahui/Final-Exam-KLBD/blob/main/Ch3_DimensionalityReduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3: Dimensionality reduction"
      ],
      "metadata": {
        "id": "DQPlQb2SnwPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After we explained about memory-based collaborative filtering algorithms, this chapter applies some of dimensionality reduction models.\n",
        "\n",
        "Here the explored models are :\n",
        "\n",
        "1. Singular Value Decomposition (SVD) : implements dimensionality reduction with Singular Value Decomposition for collaborative filtering recommender systems\n",
        "\n",
        "2. Matrix Factorization : builds and trains a Matrix Factorization based recommender system.\n",
        "\n",
        "3. Non Negative Matrix Factorization: applying non negativity to the learnt factors of matrix factorization.\n",
        "\n",
        "4. Explainable Matrix Factorization: add explainability to matrix factorization factors in order to improve recommendation performances."
      ],
      "metadata": {
        "id": "ThfbciVuqn1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Singular Value Decomposition based Collaborative Filtering"
      ],
      "metadata": {
        "id": "PG10pJuIsccV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the high level sparsity of the rating matrix $R$, **user-based** and **item-based** collaborative filtering suffer from **data sparsity** and **scalability**. These cause user and item-based collaborative filtering to be less effective and highly affect their performences. \n"
      ],
      "metadata": {
        "id": "Qix1CjUJshnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SVD algorithm**\n",
        "\n",
        "> 1. Factor the normalize rating matrix $R_{norm}$ to obtain matrices $P$, $\\Sigma$ and $Q$\n",
        "> 2. Reduce $\\Sigma$ to dimension $k$ to obtain $\\Sigma_k$\n",
        "> 3. Compute the square-root of $\\Sigma_k$ to obtain $\\Sigma_k^{\\frac{1}{2}}$\n",
        "> 4. Compute the resultant matrices $P_k\\Sigma_k^{\\frac{1}{2}}$ and $\\Sigma_k^{\\frac{1}{2}}Q_k^{\\top}$ that will be used to compute recommendation scores for any user and items."
      ],
      "metadata": {
        "id": "XIunYA6gsnfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's implement the SVD collaborative filtering"
      ],
      "metadata": {
        "id": "dtPHdfJPsx1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First we prepare the tool that we will use it."
      ],
      "metadata": {
        "id": "1A8NLgyns_hR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download useful tools"
      ],
      "metadata": {
        "id": "TozoXy0zuNmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2dPXbdlueMp",
        "outputId": "ace0703b-6aa1-4fb9-e035-354ec9281f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-01 14:26:40--  https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/nzhinusoftcm/review-on-collaborative-filtering/master/recsys.zip [following]\n",
            "--2023-01-01 14:26:40--  https://raw.githubusercontent.com/nzhinusoftcm/review-on-collaborative-filtering/master/recsys.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15312323 (15M) [application/zip]\n",
            "Saving to: ‘recsys.zip’\n",
            "\n",
            "recsys.zip          100%[===================>]  14.60M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-01-01 14:26:40 (131 MB/s) - ‘recsys.zip’ saved [15312323/15312323]\n",
            "\n",
            "Archive:  recsys.zip\n",
            "   creating: recsys/\n",
            "  inflating: recsys/datasets.py      \n",
            "  inflating: recsys/preprocessing.py  \n",
            "  inflating: recsys/utils.py         \n",
            "  inflating: recsys/requirements.txt  \n",
            "   creating: recsys/.vscode/\n",
            "  inflating: recsys/.vscode/settings.json  \n",
            "   creating: recsys/__pycache__/\n",
            "  inflating: recsys/__pycache__/datasets.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/datasets.cpython-37.pyc  \n",
            "  inflating: recsys/__pycache__/utils.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-37.pyc  \n",
            "  inflating: recsys/__pycache__/datasets.cpython-38.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-36.pyc  \n",
            "  inflating: recsys/__pycache__/preprocessing.cpython-38.pyc  \n",
            "   creating: recsys/memories/\n",
            "  inflating: recsys/memories/ItemToItem.py  \n",
            "  inflating: recsys/memories/UserToUser.py  \n",
            "   creating: recsys/memories/__pycache__/\n",
            "  inflating: recsys/memories/__pycache__/UserToUser.cpython-36.pyc  \n",
            "  inflating: recsys/memories/__pycache__/UserToUser.cpython-37.pyc  \n",
            "  inflating: recsys/memories/__pycache__/ItemToItem.cpython-37.pyc  \n",
            "  inflating: recsys/memories/__pycache__/user2user.cpython-36.pyc  \n",
            "  inflating: recsys/memories/__pycache__/ItemToItem.cpython-36.pyc  \n",
            "   creating: recsys/models/\n",
            "  inflating: recsys/models/SVD.py    \n",
            "  inflating: recsys/models/MatrixFactorization.py  \n",
            "  inflating: recsys/models/ExplainableMF.py  \n",
            "  inflating: recsys/models/NonnegativeMF.py  \n",
            "   creating: recsys/models/__pycache__/\n",
            "  inflating: recsys/models/__pycache__/SVD.cpython-36.pyc  \n",
            "  inflating: recsys/models/__pycache__/MatrixFactorization.cpython-37.pyc  \n",
            "  inflating: recsys/models/__pycache__/ExplainableMF.cpython-36.pyc  \n",
            "  inflating: recsys/models/__pycache__/ExplainableMF.cpython-37.pyc  \n",
            "  inflating: recsys/models/__pycache__/MatrixFactorization.cpython-36.pyc  \n",
            "   creating: recsys/metrics/\n",
            "  inflating: recsys/metrics/EvaluationMetrics.py  \n",
            "   creating: recsys/img/\n",
            "  inflating: recsys/img/MF-and-NNMF.png  \n",
            "  inflating: recsys/img/svd.png      \n",
            "  inflating: recsys/img/MF.png       \n",
            "   creating: recsys/predictions/\n",
            "   creating: recsys/predictions/item2item/\n",
            "   creating: recsys/weights/\n",
            "   creating: recsys/weights/item2item/\n",
            "   creating: recsys/weights/item2item/ml1m/\n",
            "  inflating: recsys/weights/item2item/ml1m/similarities.npy  \n",
            "  inflating: recsys/weights/item2item/ml1m/neighbors.npy  \n",
            "   creating: recsys/weights/item2item/ml100k/\n",
            "  inflating: recsys/weights/item2item/ml100k/similarities.npy  \n",
            "  inflating: recsys/weights/item2item/ml100k/neighbors.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import requirements\n"
      ],
      "metadata": {
        "id": "UVlQlBgHuk6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from recsys.datasets import mlLatestSmall, ml100k, ml1m\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "u1GAHn1yumCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading movielen ratings"
      ],
      "metadata": {
        "id": "QZ6sXqPSuvPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings, movies = mlLatestSmall.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SwcZVm5u0c9",
        "outputId": "12ba1215-81d2-412b-ec74-6dd9deee9d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.5%\n",
            "Successfully downloaded ml-latest-small.zip 978202 bytes.\n",
            "Unzipping the ml-latest-small.zip zip file ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how our rating matrix looks like"
      ],
      "metadata": {
        "id": "wzXf2Ixeu7KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(ratings.userid, ratings.itemid, ratings.rating, aggfunc=sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "WLEi6vWyu9M1",
        "outputId": "ecfefe38-5335-438f-d136-d7fb277ebfb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "itemid  1       2       3       4       5       6       7       8       \\\n",
              "userid                                                                   \n",
              "1          4.0     NaN     4.0     NaN     NaN     4.0     NaN     NaN   \n",
              "2          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "3          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "4          NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "5          4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
              "606        2.5     NaN     NaN     NaN     NaN     NaN     2.5     NaN   \n",
              "607        4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "608        2.5     2.0     2.0     NaN     NaN     NaN     NaN     NaN   \n",
              "609        3.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "610        5.0     NaN     NaN     NaN     NaN     5.0     NaN     NaN   \n",
              "\n",
              "itemid  9       10      ...  193565  193567  193571  193573  193579  193581  \\\n",
              "userid                  ...                                                   \n",
              "1          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "2          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "3          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "4          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "5          NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "...        ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
              "606        NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "607        NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "608        NaN     4.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "609        NaN     4.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "610        NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
              "\n",
              "itemid  193583  193585  193587  193609  \n",
              "userid                                  \n",
              "1          NaN     NaN     NaN     NaN  \n",
              "2          NaN     NaN     NaN     NaN  \n",
              "3          NaN     NaN     NaN     NaN  \n",
              "4          NaN     NaN     NaN     NaN  \n",
              "5          NaN     NaN     NaN     NaN  \n",
              "...        ...     ...     ...     ...  \n",
              "606        NaN     NaN     NaN     NaN  \n",
              "607        NaN     NaN     NaN     NaN  \n",
              "608        NaN     NaN     NaN     NaN  \n",
              "609        NaN     NaN     NaN     NaN  \n",
              "610        NaN     NaN     NaN     NaN  \n",
              "\n",
              "[610 rows x 9724 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c829f41-675b-4199-b1fa-da54265f2f9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>itemid</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>193565</th>\n",
              "      <th>193567</th>\n",
              "      <th>193571</th>\n",
              "      <th>193573</th>\n",
              "      <th>193579</th>\n",
              "      <th>193581</th>\n",
              "      <th>193583</th>\n",
              "      <th>193585</th>\n",
              "      <th>193587</th>\n",
              "      <th>193609</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>2.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607</th>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609</th>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>610 rows × 9724 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c829f41-675b-4199-b1fa-da54265f2f9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c829f41-675b-4199-b1fa-da54265f2f9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c829f41-675b-4199-b1fa-da54265f2f9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that our rating matrix has many of unobserved value. However, as we described earlier, the SVD algorithm requires that all inputs in the matrix must be defined. Let's initialize the unobserved ratings with item's average that led to better performances compared to the user's average or even a null initialization ([Sarwar et al. (2000)](http://files.grouplens.org/papers/webKDD00.pdf)).\n",
        "\n",
        "We can go further and subtrat from each rating the corresponding user mean to normalize the data. This helps to improve the accuracy of the model."
      ],
      "metadata": {
        "id": "yiufmSmdvLna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get user's mean rating\n",
        "umean = ratings.groupby(by='userid')['rating'].mean()"
      ],
      "metadata": {
        "id": "NSzqLqz9vMmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rating_matrix(ratings):\n",
        "    \"\"\"\n",
        "    1. Fill NaN values with item's average ratings\n",
        "    2. Normalize ratings by subtracting user's mean ratings\n",
        "    \n",
        "    :param ratings : DataFrame of ratings data\n",
        "    :return\n",
        "        - R : Numpy array of normalized ratings\n",
        "        - df : DataFrame of normalized ratings\n",
        "    \"\"\"\n",
        "    \n",
        "    # fill missing values with item's average ratings\n",
        "    df = pd.crosstab(ratings.userid, ratings.itemid, ratings.rating, aggfunc=sum)\n",
        "    df = df.fillna(df.mean(axis=0))\n",
        "    \n",
        "    # subtract user's mean ratings to normalize data\n",
        "    df = df.subtract(umean, axis=0)\n",
        "    \n",
        "    # convert our dataframe to numpy array\n",
        "    R = df.to_numpy()\n",
        "    \n",
        "    return R, df\n",
        "\n",
        "# generate rating matrix by calling function rating_matrix\n",
        "R, df = rating_matrix(ratings)"
      ],
      "metadata": {
        "id": "72yBkDtWvUj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$R$ is our final rating matrix. This is how the final rating matrix looks like"
      ],
      "metadata": {
        "id": "a75d32I-veAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "DV0vm_etvepJ",
        "outputId": "bb9a6978-1d5d-47ac-cbca-1322c130a8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "itemid    1         2         3         4         5         6         7       \\\n",
              "userid                                                                         \n",
              "1      -0.366379 -0.934561 -0.366379 -2.009236 -1.294951 -0.366379 -1.181194   \n",
              "2      -0.027346 -0.516458 -0.688660 -1.591133 -0.876847 -0.002197 -0.763091   \n",
              "3       1.485033  0.995921  0.823718 -0.078755  0.635531  1.510181  0.749288   \n",
              "4       0.365375 -0.123737 -0.295940 -1.198413 -0.484127  0.390523 -0.370370   \n",
              "5       0.363636 -0.204545 -0.376748 -1.279221 -0.564935  0.309715 -0.451178   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "606    -1.157399 -0.225581 -0.397784 -1.300256 -0.585971  0.288679 -1.157399   \n",
              "607     0.213904 -0.354278 -0.526481 -1.428953 -0.714668  0.159982 -0.600911   \n",
              "608    -0.634176 -1.134176 -1.134176 -0.777033 -0.062747  0.811903  0.051009   \n",
              "609    -0.270270  0.161548 -0.010655 -0.913127 -0.198842  0.675808 -0.085085   \n",
              "610     1.311444 -0.256738 -0.428941 -1.331413 -0.617127  1.311444 -0.503371   \n",
              "\n",
              "itemid    8         9         10      ...    193565    193567    193571  \\\n",
              "userid                                ...                                 \n",
              "1      -1.491379 -1.241379 -0.870167  ... -0.866379 -1.366379 -0.366379   \n",
              "2      -1.073276 -0.823276 -0.452064  ... -0.448276 -0.948276  0.051724   \n",
              "3       0.439103  0.689103  1.060315  ...  1.064103  0.564103  1.564103   \n",
              "4      -0.680556 -0.430556 -0.059343  ... -0.055556 -0.555556  0.444444   \n",
              "5      -0.761364 -0.511364 -0.140152  ... -0.136364 -0.636364  0.363636   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "606    -0.782399 -0.532399 -0.161187  ... -0.157399 -0.657399  0.342601   \n",
              "607    -0.911096 -0.661096 -0.289884  ... -0.286096 -0.786096  0.213904   \n",
              "608    -0.259176 -0.009176  0.865824  ...  0.365824 -0.134176  0.865824   \n",
              "609    -0.395270 -0.145270  0.729730  ...  0.229730 -0.270270  0.729730   \n",
              "610    -0.813556 -0.563556 -0.192344  ... -0.188556 -0.688556  0.311444   \n",
              "\n",
              "itemid    193573    193579    193581    193583    193585    193587    193609  \n",
              "userid                                                                        \n",
              "1      -0.366379 -0.866379 -0.366379 -0.866379 -0.866379 -0.866379 -0.366379  \n",
              "2       0.051724 -0.448276  0.051724 -0.448276 -0.448276 -0.448276  0.051724  \n",
              "3       1.564103  1.064103  1.564103  1.064103  1.064103  1.064103  1.564103  \n",
              "4       0.444444 -0.055556  0.444444 -0.055556 -0.055556 -0.055556  0.444444  \n",
              "5       0.363636 -0.136364  0.363636 -0.136364 -0.136364 -0.136364  0.363636  \n",
              "...          ...       ...       ...       ...       ...       ...       ...  \n",
              "606     0.342601 -0.157399  0.342601 -0.157399 -0.157399 -0.157399  0.342601  \n",
              "607     0.213904 -0.286096  0.213904 -0.286096 -0.286096 -0.286096  0.213904  \n",
              "608     0.865824  0.365824  0.865824  0.365824  0.365824  0.365824  0.865824  \n",
              "609     0.729730  0.229730  0.729730  0.229730  0.229730  0.229730  0.729730  \n",
              "610     0.311444 -0.188556  0.311444 -0.188556 -0.188556 -0.188556  0.311444  \n",
              "\n",
              "[610 rows x 9724 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc6738d1-4ef3-4acd-8fd0-a65d1a7847b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>itemid</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>193565</th>\n",
              "      <th>193567</th>\n",
              "      <th>193571</th>\n",
              "      <th>193573</th>\n",
              "      <th>193579</th>\n",
              "      <th>193581</th>\n",
              "      <th>193583</th>\n",
              "      <th>193585</th>\n",
              "      <th>193587</th>\n",
              "      <th>193609</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>userid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.366379</td>\n",
              "      <td>-0.934561</td>\n",
              "      <td>-0.366379</td>\n",
              "      <td>-2.009236</td>\n",
              "      <td>-1.294951</td>\n",
              "      <td>-0.366379</td>\n",
              "      <td>-1.181194</td>\n",
              "      <td>-1.491379</td>\n",
              "      <td>-1.241379</td>\n",
              "      <td>-0.870167</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.866379</td>\n",
              "      <td>-1.366379</td>\n",
              "      <td>-0.366379</td>\n",
              "      <td>-0.366379</td>\n",
              "      <td>-0.866379</td>\n",
              "      <td>-0.366379</td>\n",
              "      <td>-0.866379</td>\n",
              "      <td>-0.866379</td>\n",
              "      <td>-0.866379</td>\n",
              "      <td>-0.366379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.027346</td>\n",
              "      <td>-0.516458</td>\n",
              "      <td>-0.688660</td>\n",
              "      <td>-1.591133</td>\n",
              "      <td>-0.876847</td>\n",
              "      <td>-0.002197</td>\n",
              "      <td>-0.763091</td>\n",
              "      <td>-1.073276</td>\n",
              "      <td>-0.823276</td>\n",
              "      <td>-0.452064</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.448276</td>\n",
              "      <td>-0.948276</td>\n",
              "      <td>0.051724</td>\n",
              "      <td>0.051724</td>\n",
              "      <td>-0.448276</td>\n",
              "      <td>0.051724</td>\n",
              "      <td>-0.448276</td>\n",
              "      <td>-0.448276</td>\n",
              "      <td>-0.448276</td>\n",
              "      <td>0.051724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.485033</td>\n",
              "      <td>0.995921</td>\n",
              "      <td>0.823718</td>\n",
              "      <td>-0.078755</td>\n",
              "      <td>0.635531</td>\n",
              "      <td>1.510181</td>\n",
              "      <td>0.749288</td>\n",
              "      <td>0.439103</td>\n",
              "      <td>0.689103</td>\n",
              "      <td>1.060315</td>\n",
              "      <td>...</td>\n",
              "      <td>1.064103</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>1.564103</td>\n",
              "      <td>1.564103</td>\n",
              "      <td>1.064103</td>\n",
              "      <td>1.564103</td>\n",
              "      <td>1.064103</td>\n",
              "      <td>1.064103</td>\n",
              "      <td>1.064103</td>\n",
              "      <td>1.564103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.365375</td>\n",
              "      <td>-0.123737</td>\n",
              "      <td>-0.295940</td>\n",
              "      <td>-1.198413</td>\n",
              "      <td>-0.484127</td>\n",
              "      <td>0.390523</td>\n",
              "      <td>-0.370370</td>\n",
              "      <td>-0.680556</td>\n",
              "      <td>-0.430556</td>\n",
              "      <td>-0.059343</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.055556</td>\n",
              "      <td>-0.555556</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>-0.055556</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>-0.055556</td>\n",
              "      <td>-0.055556</td>\n",
              "      <td>-0.055556</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.363636</td>\n",
              "      <td>-0.204545</td>\n",
              "      <td>-0.376748</td>\n",
              "      <td>-1.279221</td>\n",
              "      <td>-0.564935</td>\n",
              "      <td>0.309715</td>\n",
              "      <td>-0.451178</td>\n",
              "      <td>-0.761364</td>\n",
              "      <td>-0.511364</td>\n",
              "      <td>-0.140152</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.136364</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>-0.136364</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>-0.136364</td>\n",
              "      <td>-0.136364</td>\n",
              "      <td>-0.136364</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>-1.157399</td>\n",
              "      <td>-0.225581</td>\n",
              "      <td>-0.397784</td>\n",
              "      <td>-1.300256</td>\n",
              "      <td>-0.585971</td>\n",
              "      <td>0.288679</td>\n",
              "      <td>-1.157399</td>\n",
              "      <td>-0.782399</td>\n",
              "      <td>-0.532399</td>\n",
              "      <td>-0.161187</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.157399</td>\n",
              "      <td>-0.657399</td>\n",
              "      <td>0.342601</td>\n",
              "      <td>0.342601</td>\n",
              "      <td>-0.157399</td>\n",
              "      <td>0.342601</td>\n",
              "      <td>-0.157399</td>\n",
              "      <td>-0.157399</td>\n",
              "      <td>-0.157399</td>\n",
              "      <td>0.342601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607</th>\n",
              "      <td>0.213904</td>\n",
              "      <td>-0.354278</td>\n",
              "      <td>-0.526481</td>\n",
              "      <td>-1.428953</td>\n",
              "      <td>-0.714668</td>\n",
              "      <td>0.159982</td>\n",
              "      <td>-0.600911</td>\n",
              "      <td>-0.911096</td>\n",
              "      <td>-0.661096</td>\n",
              "      <td>-0.289884</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.286096</td>\n",
              "      <td>-0.786096</td>\n",
              "      <td>0.213904</td>\n",
              "      <td>0.213904</td>\n",
              "      <td>-0.286096</td>\n",
              "      <td>0.213904</td>\n",
              "      <td>-0.286096</td>\n",
              "      <td>-0.286096</td>\n",
              "      <td>-0.286096</td>\n",
              "      <td>0.213904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>-0.634176</td>\n",
              "      <td>-1.134176</td>\n",
              "      <td>-1.134176</td>\n",
              "      <td>-0.777033</td>\n",
              "      <td>-0.062747</td>\n",
              "      <td>0.811903</td>\n",
              "      <td>0.051009</td>\n",
              "      <td>-0.259176</td>\n",
              "      <td>-0.009176</td>\n",
              "      <td>0.865824</td>\n",
              "      <td>...</td>\n",
              "      <td>0.365824</td>\n",
              "      <td>-0.134176</td>\n",
              "      <td>0.865824</td>\n",
              "      <td>0.865824</td>\n",
              "      <td>0.365824</td>\n",
              "      <td>0.865824</td>\n",
              "      <td>0.365824</td>\n",
              "      <td>0.365824</td>\n",
              "      <td>0.365824</td>\n",
              "      <td>0.865824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609</th>\n",
              "      <td>-0.270270</td>\n",
              "      <td>0.161548</td>\n",
              "      <td>-0.010655</td>\n",
              "      <td>-0.913127</td>\n",
              "      <td>-0.198842</td>\n",
              "      <td>0.675808</td>\n",
              "      <td>-0.085085</td>\n",
              "      <td>-0.395270</td>\n",
              "      <td>-0.145270</td>\n",
              "      <td>0.729730</td>\n",
              "      <td>...</td>\n",
              "      <td>0.229730</td>\n",
              "      <td>-0.270270</td>\n",
              "      <td>0.729730</td>\n",
              "      <td>0.729730</td>\n",
              "      <td>0.229730</td>\n",
              "      <td>0.729730</td>\n",
              "      <td>0.229730</td>\n",
              "      <td>0.229730</td>\n",
              "      <td>0.229730</td>\n",
              "      <td>0.729730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>1.311444</td>\n",
              "      <td>-0.256738</td>\n",
              "      <td>-0.428941</td>\n",
              "      <td>-1.331413</td>\n",
              "      <td>-0.617127</td>\n",
              "      <td>1.311444</td>\n",
              "      <td>-0.503371</td>\n",
              "      <td>-0.813556</td>\n",
              "      <td>-0.563556</td>\n",
              "      <td>-0.192344</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.188556</td>\n",
              "      <td>-0.688556</td>\n",
              "      <td>0.311444</td>\n",
              "      <td>0.311444</td>\n",
              "      <td>-0.188556</td>\n",
              "      <td>0.311444</td>\n",
              "      <td>-0.188556</td>\n",
              "      <td>-0.188556</td>\n",
              "      <td>-0.188556</td>\n",
              "      <td>0.311444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>610 rows × 9724 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc6738d1-4ef3-4acd-8fd0-a65d1a7847b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc6738d1-4ef3-4acd-8fd0-a65d1a7847b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc6738d1-4ef3-4acd-8fd0-a65d1a7847b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ids encoding"
      ],
      "metadata": {
        "id": "A5DRYmYPvo1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's encode users and items ids such that their values range from 0 to 909 (for users) and from 0 to 9723 (for items)"
      ],
      "metadata": {
        "id": "gGdK1C_0vswJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users = sorted(ratings['userid'].unique())\n",
        "items = sorted(ratings['itemid'].unique())\n",
        "\n",
        "# create our id encoders\n",
        "uencoder = LabelEncoder()\n",
        "iencoder = LabelEncoder()\n",
        "\n",
        "# fit our label encoder\n",
        "uencoder.fit(users)\n",
        "iencoder.fit(items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POYBbDKcvwH1",
        "outputId": "38bbaec9-72ca-42c5-8708-ad28cd09b2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVD Algorithm"
      ],
      "metadata": {
        "id": "LnB0dnrtwCT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our rating data has been normalize and that missing values has been filled, we can apply the SVD algorithm. Several libraries may be useful such as ```numpy```, ```scipy```, ```sklearn```, ... Let's try it with ```numpy```.\n",
        "\n",
        "In our SVD class we provide the following function :\n",
        "\n",
        "1. ```fit()``` : compute the svd of the rating matrix and save the resultant matrices P, S and Qh (Q transpose) as attributs of the SVD class.\n",
        "2. ```predict()```: use matrices P, S and Qh to make ratin prediction for a given $u$ user on an item $i$. Computations are made over encoded values of userid and itemid. The predicted value is the dot product between $u^{th}$ row of $P.\\sqrt{S}$ and the $i^{th}$ column of $\\sqrt{S}.Qh$. **Note** that since we normalized rating before applying SVD, the predicted value will also be normalize. So, to get the final predicted rating, we have to add to the predicted value the mean rating of user $u$.\n",
        "3. ```recommend()```: use matrices P, S and Qh to make recommendations to a given user. The recommended items are those that where not rated by the user and received a high score according to the svd model."
      ],
      "metadata": {
        "id": "SlPJiCIswEXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SVD:\n",
        "    \n",
        "    def __init__(self, umeam):\n",
        "        \"\"\"\n",
        "        :param\n",
        "            - umean : mean ratings of users\n",
        "        \"\"\"\n",
        "        self.umean = umean.to_numpy()\n",
        "        \n",
        "        # init svd resultant matrices\n",
        "        self.P = np.array([])\n",
        "        self.S = np.array([])\n",
        "        self.Qh = np.array([])\n",
        "        \n",
        "        # init users and items latent factors\n",
        "        self.u_factors = np.array([])\n",
        "        self.i_factors = np.array([])\n",
        "    \n",
        "    def fit(self, R):\n",
        "        \"\"\"\n",
        "        Fit the SVD model with rating matrix R\n",
        "        \"\"\"\n",
        "        P, s, Qh = np.linalg.svd(R, full_matrices=False)\n",
        "        \n",
        "        self.P = P\n",
        "        self.S = np.diag(s)\n",
        "        self.Qh = Qh\n",
        "        \n",
        "        # latent factors of users (u_factors) and items (i_factors)\n",
        "        self.u_factors = np.dot(self.P, np.sqrt(self.S))\n",
        "        self.i_factors = np.dot(np.sqrt(self.S), self.Qh)\n",
        "    \n",
        "    def predict(self, userid, itemid):\n",
        "        \"\"\"\n",
        "        Make rating prediction for a given user on an item\n",
        "        \n",
        "        :param\n",
        "            - userid : user's id\n",
        "            - itemid : item's id\n",
        "            \n",
        "        :return\n",
        "            - r_hat : predicted rating\n",
        "        \"\"\"\n",
        "        # encode user and item ids\n",
        "        u = uencoder.transform([userid])[0]\n",
        "        i = iencoder.transform([itemid])[0]\n",
        "        \n",
        "        # the predicted rating is the dot product between the uth row \n",
        "        # of u_factors and the ith column of i_factors\n",
        "        r_hat = np.dot(self.u_factors[u,:], self.i_factors[:,i])\n",
        "        \n",
        "        # add the mean rating of user u to the predicted value\n",
        "        r_hat += self.umean[u]\n",
        "        \n",
        "        return r_hat\n",
        "        \n",
        "    \n",
        "    def recommend(self, userid):\n",
        "        \"\"\"\n",
        "        :param\n",
        "            - userid : user's id\n",
        "        \"\"\"\n",
        "        # encode user\n",
        "        u = uencoder.transform([userid])[0]\n",
        "        \n",
        "        # the dot product between the uth row of u_factors and i_factors returns\n",
        "        # the predicted value for user u on all items        \n",
        "        predictions = np.dot(self.u_factors[u,:], self.i_factors) + self.umean[u]\n",
        "        \n",
        "        # sort item ids in decreasing order of predictions\n",
        "        top_idx = np.flip(np.argsort(predictions))\n",
        "\n",
        "        # decode indices to get their corresponding itemids\n",
        "        top_items = iencoder.inverse_transform(top_idx)\n",
        "        \n",
        "        # sorted predictions\n",
        "        preds = predictions[top_idx]\n",
        "        \n",
        "        return top_items, preds\n",
        "        "
      ],
      "metadata": {
        "id": "ixwCfhO2wQ_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create our SVD model and provide to it user's mean rating; Fit the model with the normalized rating matrix $R$."
      ],
      "metadata": {
        "id": "NOPt9e61wVK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create our svd model\n",
        "svd = SVD(umean)\n",
        "\n",
        "# fit our model with normalized ratings\n",
        "svd.fit(R)"
      ],
      "metadata": {
        "id": "s_UCAXlswV6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rating prediction"
      ],
      "metadata": {
        "id": "fCeB5XB8wsa5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model has been fitted.\n",
        "Let's make some predictions for users using function ```predict``` of our SVD class. Here are some truth ratings"
      ],
      "metadata": {
        "id": "dldfof3Twwx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ZaoI81ENw5R9",
        "outputId": "5dc62af0-9720-481c-94a2-aa570a64bcdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userid  itemid  rating  timestamp\n",
              "0       1       1     4.0  964982703\n",
              "1       1       3     4.0  964981247\n",
              "2       1       6     4.0  964982224\n",
              "3       1      47     5.0  964983815\n",
              "4       1      50     5.0  964982931\n",
              "5       1      70     3.0  964982400\n",
              "6       1     101     5.0  964980868\n",
              "7       1     110     4.0  964982176\n",
              "8       1     151     5.0  964984041\n",
              "9       1     157     5.0  964984100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02bfd127-9d4e-486f-962c-5c1ee224b2a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>itemid</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>3.0</td>\n",
              "      <td>964982400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964980868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>110</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964984041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>157</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964984100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02bfd127-9d4e-486f-962c-5c1ee224b2a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02bfd127-9d4e-486f-962c-5c1ee224b2a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02bfd127-9d4e-486f-962c-5c1ee224b2a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's apply our model to make see if our predictions make sens. We will make predictions for user 1 on the 10 items listed above."
      ],
      "metadata": {
        "id": "ZYk58lOcw9V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# user for which we make predictions\n",
        "userid = 1\n",
        "\n",
        "# list of items for which we are making predictions for user 1\n",
        "items = [1,3,6,47,50,70,101,110,151,157]\n",
        "\n",
        "# predictions\n",
        "for itemid in items:\n",
        "    r = svd.predict(userid=userid, itemid=itemid)\n",
        "    print('prediction for userid={} and itemid={} : {}'.format(userid, itemid, r))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN4aPE6zw99m",
        "outputId": "350ffb05-fb88-4c7d-c2e7-8d5b946f233b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction for userid=1 and itemid=1 : 3.9999999999999996\n",
            "prediction for userid=1 and itemid=3 : 4.0000000000000036\n",
            "prediction for userid=1 and itemid=6 : 3.9999999999999867\n",
            "prediction for userid=1 and itemid=47 : 5.0\n",
            "prediction for userid=1 and itemid=50 : 4.9999999999999964\n",
            "prediction for userid=1 and itemid=70 : 2.999999999999981\n",
            "prediction for userid=1 and itemid=101 : 5.000000000000006\n",
            "prediction for userid=1 and itemid=110 : 3.9999999999999862\n",
            "prediction for userid=1 and itemid=151 : 5.0000000000000115\n",
            "prediction for userid=1 and itemid=157 : 5.000000000000028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prediction error is less than 0.00001"
      ],
      "metadata": {
        "id": "wSpiKl1UxEMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make recommendations"
      ],
      "metadata": {
        "id": "2y6NhlwyxLr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ```recommend``` function makes recommendations for a given user."
      ],
      "metadata": {
        "id": "DXfk3BK5xNDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "userid = 1\n",
        "\n",
        "# items sorted in decreasing order of predictions for user 1\n",
        "sorted_items, preds = svd.recommend(userid=userid)\n",
        "\n",
        "##\n",
        "# Now let's exclud from that sorted list items already purchased by the user\n",
        "##\n",
        "\n",
        "# list of items rated by the user\n",
        "uitems = ratings.loc[ratings.userid == userid].itemid.to_list()\n",
        "\n",
        "# remove from sorted_items items already in uitems and pick the top 30 ones\n",
        "# as recommendation list\n",
        "top30 = np.setdiff1d(sorted_items, uitems, assume_unique=True)[:30]\n",
        "\n",
        "# get corresponding predictions from the top30 items\n",
        "top30_idx = list(np.where(sorted_items == idx)[0][0] for idx in top30)\n",
        "top30_predictions = preds[top30_idx]\n",
        "\n",
        "# find corresponding movie titles\n",
        "zipped_top30 = list(zip(top30,top30_predictions))\n",
        "top30 = pd.DataFrame(zipped_top30, columns=['itemid','predictions'])\n",
        "List = pd.merge(top30, movies, on='itemid', how='inner')\n",
        "\n",
        "# show the list\n",
        "List"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "TRAKZp_LxPG9",
        "outputId": "c43cd833-757e-4ebf-b492-9032e765cccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    itemid  predictions                                              title  \\\n",
              "0      148          5.0                   Awfully Big Adventure, An (1995)   \n",
              "1     6086          5.0                                 I, the Jury (1982)   \n",
              "2   136445          5.0                 George Carlin: Back in Town (1996)   \n",
              "3     6201          5.0                                   Lady Jane (1986)   \n",
              "4     2075          5.0                                    Mephisto (1981)   \n",
              "5     6192          5.0          Open Hearts (Elsker dig for evigt) (2002)   \n",
              "6   117531          5.0                                   Watermark (2014)   \n",
              "7   158398          5.0                              World of Glory (1991)   \n",
              "8     6021          5.0  American Friend, The (Amerikanische Freund, De...   \n",
              "9   136556          5.0       Kung Fu Panda: Secrets of the Masters (2011)   \n",
              "10  136447          5.0         George Carlin: You Are All Diseased (1999)   \n",
              "11  136503          5.0           Tom and Jerry: Shiver Me Whiskers (2006)   \n",
              "12  134095          5.0                                     My Love (2006)   \n",
              "13    3851          5.0                     I'm the One That I Want (2000)   \n",
              "14  136469          5.0           Larry David: Curb Your Enthusiasm (1999)   \n",
              "15  158882          5.0                                   All Yours (2016)   \n",
              "16  134004          5.0                                What Love Is (2007)   \n",
              "17   67618          5.0                             Strictly Sexual (2008)   \n",
              "18    3567          5.0                                  Bossa Nova (2000)   \n",
              "19  158027          5.0                  SORI: Voice from the Heart (2016)   \n",
              "20   59814          5.0                                  Ex Drummer (2007)   \n",
              "21    5745          5.0                           Four Seasons, The (1981)   \n",
              "22  118894          5.0                 Scooby-Doo! Abracadabra-Doo (2010)   \n",
              "23    5746          5.0                    Galaxy of Terror (Quest) (1981)   \n",
              "24  118834          5.0                  National Lampoon's Bag Boy (2007)   \n",
              "25    3940          5.0                  Slumber Party Massacre III (1990)   \n",
              "26   95311          5.0                                      Presto (2008)   \n",
              "27    3496          5.0                            Madame Sousatzka (1988)   \n",
              "28  156025          5.0              Ice Age: The Great Egg-Scapade (2016)   \n",
              "29    2196          5.0                                   Knock Off (1998)   \n",
              "\n",
              "                                 genres  \n",
              "0                                 Drama  \n",
              "1                  Crime|Drama|Thriller  \n",
              "2                                Comedy  \n",
              "3                         Drama|Romance  \n",
              "4                             Drama|War  \n",
              "5                               Romance  \n",
              "6                           Documentary  \n",
              "7                                Comedy  \n",
              "8          Crime|Drama|Mystery|Thriller  \n",
              "9                    Animation|Children  \n",
              "10                               Comedy  \n",
              "11            Animation|Children|Comedy  \n",
              "12                      Animation|Drama  \n",
              "13                               Comedy  \n",
              "14                               Comedy  \n",
              "15                 Comedy|Drama|Romance  \n",
              "16                       Comedy|Romance  \n",
              "17                 Comedy|Drama|Romance  \n",
              "18                 Comedy|Drama|Romance  \n",
              "19                         Drama|Sci-Fi  \n",
              "20            Comedy|Crime|Drama|Horror  \n",
              "21                         Comedy|Drama  \n",
              "22           Animation|Children|Mystery  \n",
              "23         Action|Horror|Mystery|Sci-Fi  \n",
              "24                               Comedy  \n",
              "25                               Horror  \n",
              "26    Animation|Children|Comedy|Fantasy  \n",
              "27                                Drama  \n",
              "28  Adventure|Animation|Children|Comedy  \n",
              "29                               Action  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9c9fec5-fd1f-46bd-a031-cd643c208bec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemid</th>\n",
              "      <th>predictions</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Awfully Big Adventure, An (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6086</td>\n",
              "      <td>5.0</td>\n",
              "      <td>I, the Jury (1982)</td>\n",
              "      <td>Crime|Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>136445</td>\n",
              "      <td>5.0</td>\n",
              "      <td>George Carlin: Back in Town (1996)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6201</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Lady Jane (1986)</td>\n",
              "      <td>Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2075</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Mephisto (1981)</td>\n",
              "      <td>Drama|War</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6192</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Open Hearts (Elsker dig for evigt) (2002)</td>\n",
              "      <td>Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>117531</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Watermark (2014)</td>\n",
              "      <td>Documentary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>158398</td>\n",
              "      <td>5.0</td>\n",
              "      <td>World of Glory (1991)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6021</td>\n",
              "      <td>5.0</td>\n",
              "      <td>American Friend, The (Amerikanische Freund, De...</td>\n",
              "      <td>Crime|Drama|Mystery|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>136556</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Kung Fu Panda: Secrets of the Masters (2011)</td>\n",
              "      <td>Animation|Children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>136447</td>\n",
              "      <td>5.0</td>\n",
              "      <td>George Carlin: You Are All Diseased (1999)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>136503</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Tom and Jerry: Shiver Me Whiskers (2006)</td>\n",
              "      <td>Animation|Children|Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>134095</td>\n",
              "      <td>5.0</td>\n",
              "      <td>My Love (2006)</td>\n",
              "      <td>Animation|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3851</td>\n",
              "      <td>5.0</td>\n",
              "      <td>I'm the One That I Want (2000)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>136469</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Larry David: Curb Your Enthusiasm (1999)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>158882</td>\n",
              "      <td>5.0</td>\n",
              "      <td>All Yours (2016)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>134004</td>\n",
              "      <td>5.0</td>\n",
              "      <td>What Love Is (2007)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>67618</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Strictly Sexual (2008)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3567</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Bossa Nova (2000)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>158027</td>\n",
              "      <td>5.0</td>\n",
              "      <td>SORI: Voice from the Heart (2016)</td>\n",
              "      <td>Drama|Sci-Fi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>59814</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ex Drummer (2007)</td>\n",
              "      <td>Comedy|Crime|Drama|Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>5745</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Four Seasons, The (1981)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>118894</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Scooby-Doo! Abracadabra-Doo (2010)</td>\n",
              "      <td>Animation|Children|Mystery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>5746</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Galaxy of Terror (Quest) (1981)</td>\n",
              "      <td>Action|Horror|Mystery|Sci-Fi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>118834</td>\n",
              "      <td>5.0</td>\n",
              "      <td>National Lampoon's Bag Boy (2007)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3940</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Slumber Party Massacre III (1990)</td>\n",
              "      <td>Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>95311</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Presto (2008)</td>\n",
              "      <td>Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3496</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Madame Sousatzka (1988)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>156025</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ice Age: The Great Egg-Scapade (2016)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2196</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Knock Off (1998)</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9c9fec5-fd1f-46bd-a031-cd643c208bec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9c9fec5-fd1f-46bd-a031-cd643c208bec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9c9fec5-fd1f-46bd-a031-cd643c208bec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first 30 items have an equivalent rating prediction for the user 1"
      ],
      "metadata": {
        "id": "-7tjml8wxUzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Matrix Factorization"
      ],
      "metadata": {
        "id": "P08Dx0_vxhrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>User-based</b> and <b>Item-based</b> collaborative Filtering recommender systems suffer from <i>data sparsity</i> and <i>scalability</i> for online recommendations. <b>Matrix Factorization</b> helps to address these drawbacks of memory-based collaborative filtering by reducing the dimension of the rating matrix $R$."
      ],
      "metadata": {
        "id": "_rv-h4w1x5P5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The movielen lasted small dataset has 100k ratings of $m=610$ users on $n=9724$ items. The rating matrix in then a $m\\times n$ matrix (i.e $R\\in \\mathbb{R}^{m\\times n}$). The fact that users usually interact with less than $1\\%$ of items leads the rating matrix $R$ to be highly sparse."
      ],
      "metadata": {
        "id": "DFiitTQ-yt85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Matrix Factorization : algorithm**\n",
        "1. Initialize $P$ and $Q$ with random values\n",
        "2. For each training example $(u,i)\\in\\kappa$ with the corresponding rating $r_{u,i}$:\n",
        "   \n",
        "\n",
        "   *   compute $\\hat{r}_{u,i}$ as $\\hat{r}_{u,i} = q_{i}^{\\top} p_u$\n",
        "\n",
        "   *   compute the error : $e_{u,i} = |r_{ui} - \\hat{r}_{u,i}|$\n",
        "   *   update $p_u$ and $q_i$:\n",
        "\n",
        "       - $p_u \\leftarrow p_u + \\alpha\\cdot (e_{u,i}\\cdot q_i-\\lambda \\cdot p_u)$ \n",
        "       - $q_i \\leftarrow q_i + \\alpha\\cdot (e_{u,i}\\cdot p_u-\\lambda \\cdot q_i)$ \n",
        "        \n",
        "3. Repeat step 2 until the optimal parameters are reached. \n",
        "\n"
      ],
      "metadata": {
        "id": "pY88hJ33zimE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First we prepare the tool that we will use it."
      ],
      "metadata": {
        "id": "4l5QwmJh0v4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Download useful files**"
      ],
      "metadata": {
        "id": "KqvXlumg0xgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ],
      "metadata": {
        "id": "bCmWEUpj02fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Import requirements**"
      ],
      "metadata": {
        "id": "hm7DLy6I05vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from recsys.preprocessing import mean_ratings\n",
        "from recsys.preprocessing import normalized_ratings\n",
        "from recsys.preprocessing import ids_encoder\n",
        "from recsys.preprocessing import train_test_split\n",
        "from recsys.preprocessing import rating_matrix\n",
        "from recsys.preprocessing import get_examples\n",
        "from recsys.preprocessing import scale_ratings\n",
        "\n",
        "from recsys.datasets import ml100k\n",
        "from recsys.datasets import ml1m\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "ejhJIjRR08Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model definition"
      ],
      "metadata": {
        "id": "G-9UItoA0_kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MatrixFactorization:\n",
        "    \n",
        "    def __init__(self, m, n, k=10, alpha=0.001, lamb=0.01):\n",
        "        \"\"\"\n",
        "        Initialization of the model        \n",
        "        : param\n",
        "            - m : number of users\n",
        "            - n : number of items\n",
        "            - k : length of latent factor, both for users and items. 50 by default\n",
        "            - alpha : learning rate. 0.001 by default\n",
        "            - lamb : regularizer parameter. 0.02 by default\n",
        "        \"\"\"\n",
        "        np.random.seed(32)\n",
        "        \n",
        "        # initialize the latent factor matrices P and Q (of shapes (m,k) and (n,k) respectively) that will be learnt\n",
        "        self.k = k\n",
        "        self.P = np.random.normal(size=(m, k))\n",
        "        self.Q = np.random.normal(size=(n, k))\n",
        "        \n",
        "        # hyperparameter initialization\n",
        "        self.alpha = alpha\n",
        "        self.lamb = lamb\n",
        "        \n",
        "        # training history\n",
        "        self.history = {\n",
        "            \"epochs\":[],\n",
        "            \"loss\":[],\n",
        "            \"val_loss\":[],\n",
        "            \"lr\":[]\n",
        "        }\n",
        "    \n",
        "    def print_training_parameters(self):\n",
        "        print('Training Matrix Factorization Model ...')\n",
        "        print(f'k={self.k} \\t alpha={self.alpha} \\t lambda={self.lamb}')\n",
        "    \n",
        "    def update_rule(self, u, i, error):\n",
        "        self.P[u] = self.P[u] + self.alpha * (error * self.Q[i] - self.lamb * self.P[u])\n",
        "        self.Q[i] = self.Q[i] + self.alpha * (error * self.P[u] - self.lamb * self.Q[i])\n",
        "        \n",
        "    def mae(self,  x_train, y_train):\n",
        "        \"\"\"\n",
        "        returns the Mean Absolute Error\n",
        "        \"\"\"\n",
        "        # number of training exemples\n",
        "        M = x_train.shape[0]\n",
        "        error = 0\n",
        "        for pair, r in zip(x_train, y_train):\n",
        "            u, i = pair\n",
        "            error += abs(r - np.dot(self.P[u], self.Q[i]))\n",
        "        return error/M\n",
        "    \n",
        "    def print_training_progress(self, epoch, epochs, error, val_error, steps=5):\n",
        "        if epoch == 1 or epoch % steps == 0 :\n",
        "                print(\"epoch {}/{} - loss : {} - val_loss : {}\".format(epoch, epochs, round(error,3), round(val_error,3)))\n",
        "                \n",
        "    def learning_rate_schedule(self, epoch, target_epochs = 20):\n",
        "        if (epoch >= target_epochs) and (epoch % target_epochs == 0):\n",
        "                factor = epoch // target_epochs\n",
        "                self.alpha = self.alpha * (1 / (factor * 20))\n",
        "                print(\"\\nLearning Rate : {}\\n\".format(self.alpha))\n",
        "    \n",
        "    def fit(self, x_train, y_train, validation_data, epochs=1000):\n",
        "        \"\"\"\n",
        "        Train latent factors P and Q according to the training set\n",
        "        \n",
        "        :param\n",
        "            - x_train : training pairs (u,i) for which rating r_ui is known\n",
        "            - y_train : set of ratings r_ui for all training pairs (u,i)\n",
        "            - validation_data : tuple (x_test, y_test)\n",
        "            - epochs : number of time to loop over the entire training set. \n",
        "            1000 epochs by default\n",
        "            \n",
        "        Note that u and i are encoded values of userid and itemid\n",
        "        \"\"\"\n",
        "        self.print_training_parameters()\n",
        "        \n",
        "        # validation data\n",
        "        x_test, y_test = validation_data\n",
        "        \n",
        "        # loop over the number of epochs\n",
        "        for epoch in range(1, epochs+1):\n",
        "            \n",
        "            # for each pair (u,i) and the corresponding rating r\n",
        "            for pair, r in zip(x_train, y_train):\n",
        "                \n",
        "                # get encoded values of userid and itemid from pair\n",
        "                u,i = pair\n",
        "                \n",
        "                # compute the predicted rating r_hat\n",
        "                r_hat = np.dot(self.P[u], self.Q[i])\n",
        "                \n",
        "                # compute the prediction error\n",
        "                e = abs(r - r_hat)\n",
        "                \n",
        "                # update rules\n",
        "                self.update_rule(u, i, e)\n",
        "                \n",
        "            # training and validation error  after this epochs\n",
        "            error = self.mae(x_train, y_train)\n",
        "            val_error = self.mae(x_test, y_test)\n",
        "            \n",
        "            # update history\n",
        "            self.history['epochs'].append(epoch)\n",
        "            self.history['loss'].append(error)\n",
        "            self.history['val_loss'].append(val_error)\n",
        "            \n",
        "            # update history\n",
        "            self.update_history(epoch, error, val_error)\n",
        "            \n",
        "            # print training progress after each steps epochs\n",
        "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
        "              \n",
        "            # leaning rate scheduler : redure the learning rate as we go deeper in the number of epochs\n",
        "            # self.learning_rate_schedule(epoch)\n",
        "        \n",
        "        return self.history\n",
        "    \n",
        "    def update_history(self, epoch, error, val_error):\n",
        "        self.history['epochs'].append(epoch)\n",
        "        self.history['loss'].append(error)\n",
        "        self.history['val_loss'].append(val_error)\n",
        "        self.history['lr'].append(self.alpha)\n",
        "    \n",
        "    def evaluate(self, x_test, y_test):\n",
        "        \"\"\"\n",
        "        compute the global error on the test set        \n",
        "        :param x_test : test pairs (u,i) for which rating r_ui is known\n",
        "        :param y_test : set of ratings r_ui for all test pairs (u,i)\n",
        "        \"\"\"\n",
        "        error = self.mae(x_test, y_test)\n",
        "        print(f\"validation error : {round(error,3)}\")\n",
        "        \n",
        "        return error\n",
        "      \n",
        "    def predict(self, userid, itemid):\n",
        "        \"\"\"\n",
        "        Make rating prediction for a user on an item\n",
        "        :param userid\n",
        "        :param itemid\n",
        "        :return r : predicted rating\n",
        "        \"\"\"\n",
        "        # encode user and item ids to be able to access their latent factors in\n",
        "        # matrices P and Q\n",
        "        u = uencoder.transform([userid])[0]\n",
        "        i = iencoder.transform([itemid])[0]\n",
        "\n",
        "        # rating prediction using encoded ids. Dot product between P_u and Q_i\n",
        "        r = np.dot(self.P[u], self.Q[i])\n",
        "        return r\n",
        "\n",
        "    def recommend(self, userid, N=30):\n",
        "        \"\"\"\n",
        "        make to N recommendations for a given user\n",
        "\n",
        "        :return(top_items,preds) : top N items with the highest predictions \n",
        "        with their corresponding predictions\n",
        "        \"\"\"\n",
        "        # encode the userid\n",
        "        u = uencoder.transform([userid])[0]\n",
        "\n",
        "        # predictions for users userid on all product\n",
        "        predictions = np.dot(self.P[u], self.Q.T)\n",
        "\n",
        "        # get the indices of the top N predictions\n",
        "        top_idx = np.flip(np.argsort(predictions))[:N]\n",
        "\n",
        "        # decode indices to get their corresponding itemids\n",
        "        top_items = iencoder.inverse_transform(top_idx)\n",
        "\n",
        "        # take corresponding predictions for top N indices\n",
        "        preds = predictions[top_idx]\n",
        "\n",
        "        return top_items, preds        "
      ],
      "metadata": {
        "id": "Dk5bbmoa1Bvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "Qfrf4MeS1FZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. MovieLens 100k"
      ],
      "metadata": {
        "id": "5_qyFrSb1G7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evaluation on raw ratings**"
      ],
      "metadata": {
        "id": "LolIHCnV1QS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the ml100k dataset\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "m = ratings.userid.nunique()   # total number of users\n",
        "n = ratings.itemid.nunique()   # total number of items\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsX7gnnu1URh",
        "outputId": "2857f34f-8f99-45bf-c73e-ff35646037c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.2%\n",
            "Successfully downloaded ml-100k.zip 4924029 bytes.\n",
            "Unzipping the ml-100k.zip zip file ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit the model on the training set\n",
        "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pb56HVr1XUK",
        "outputId": "c543be89-70a9-47fb-da46-36f777bb3068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Matrix Factorization Model ...\n",
            "k=10 \t alpha=0.01 \t lambda=1.5\n",
            "epoch 1/10 - loss : 2.734 - val_loss : 2.779\n",
            "epoch 2/10 - loss : 1.764 - val_loss : 1.794\n",
            "epoch 3/10 - loss : 1.592 - val_loss : 1.614\n",
            "epoch 4/10 - loss : 1.538 - val_loss : 1.556\n",
            "epoch 5/10 - loss : 1.515 - val_loss : 1.531\n",
            "epoch 6/10 - loss : 1.503 - val_loss : 1.517\n",
            "epoch 7/10 - loss : 1.496 - val_loss : 1.509\n",
            "epoch 8/10 - loss : 1.491 - val_loss : 1.504\n",
            "epoch 9/10 - loss : 1.488 - val_loss : 1.5\n",
            "epoch 10/10 - loss : 1.486 - val_loss : 1.497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MF.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReoLY0rY1hrl",
        "outputId": "244b3602-6aba-4198-dad7-d0488c410602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 1.497\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4973507972141993"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the validation error is 1.497, it means that on average, the model's predictions are off by 1.497 units."
      ],
      "metadata": {
        "id": "K5-sW-w22MZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evaluation on normalized ratings**"
      ],
      "metadata": {
        "id": "j23cJFXj2NEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "m = ratings['userid'].nunique()   # total number of users\n",
        "n = ratings['itemid'].nunique()   # total number of items\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "iMKhUhWp2Vq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit the model on the training set\n",
        "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vISqpXHh2YAZ",
        "outputId": "8e1b365f-874c-40b1-c62c-69dde48345c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Matrix Factorization Model ...\n",
            "k=10 \t alpha=0.01 \t lambda=1.5\n",
            "epoch 1/10 - loss : 0.851 - val_loss : 0.847\n",
            "epoch 2/10 - loss : 0.831 - val_loss : 0.831\n",
            "epoch 3/10 - loss : 0.828 - val_loss : 0.829\n",
            "epoch 4/10 - loss : 0.827 - val_loss : 0.828\n",
            "epoch 5/10 - loss : 0.827 - val_loss : 0.828\n",
            "epoch 6/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 7/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 8/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 9/10 - loss : 0.826 - val_loss : 0.828\n",
            "epoch 10/10 - loss : 0.826 - val_loss : 0.828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MF.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBvfz6ox2jje",
        "outputId": "170bc5d5-32a1-4e07-8ce3-cfd53c53ad10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 0.828\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8276982643684648"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the validation error is 0.828, it means that on average, the model's predictions are off by 0.828 units."
      ],
      "metadata": {
        "id": "MlmyBtgw2mXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. MovieLens 1M"
      ],
      "metadata": {
        "id": "Mbg6b1U-2tyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evaluation on raw data**"
      ],
      "metadata": {
        "id": "ElZ4xqa92yve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the ml1m dataset\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "m = ratings.userid.nunique()   # total number of users\n",
        "n = ratings.itemid.nunique()   # total number of items\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxenCQLB23cV",
        "outputId": "e36af846-1d68-424e-991e-70a55b991ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download data 100.1%\n",
            "Successfully downloaded ml-1m.zip 5917549 bytes.\n",
            "Unzipping the ml-1m.zip zip file ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit the model on the training set\n",
        "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2H6gW6H27Qt",
        "outputId": "f957fa7e-218e-48ae-85e9-0cff354532e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Matrix Factorization Model ...\n",
            "k=10 \t alpha=0.01 \t lambda=1.5\n",
            "epoch 1/10 - loss : 1.713 - val_loss : 1.718\n",
            "epoch 2/10 - loss : 1.523 - val_loss : 1.526\n",
            "epoch 3/10 - loss : 1.496 - val_loss : 1.498\n",
            "epoch 4/10 - loss : 1.489 - val_loss : 1.489\n",
            "epoch 5/10 - loss : 1.485 - val_loss : 1.486\n",
            "epoch 6/10 - loss : 1.484 - val_loss : 1.484\n",
            "epoch 7/10 - loss : 1.483 - val_loss : 1.483\n",
            "epoch 8/10 - loss : 1.483 - val_loss : 1.483\n",
            "epoch 9/10 - loss : 1.482 - val_loss : 1.482\n",
            "epoch 10/10 - loss : 1.482 - val_loss : 1.482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MF.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LboCpHp539i1",
        "outputId": "0b5ca9cf-d10e-447f-f1e3-2efafdd59dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 1.482\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4820034560467208"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the validation error is 1.482, it means that on average, the model's predictions are off by 1.482 units."
      ],
      "metadata": {
        "id": "adYU0Mhp3_U1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Evaluation on normalized ratings**"
      ],
      "metadata": {
        "id": "774dljFl4EYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "m = ratings['userid'].nunique()   # total number of users\n",
        "n = ratings['itemid'].nunique()   # total number of items\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "DF1Huw2Z4IbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "MF = MatrixFactorization(m, n, k=10, alpha=0.01, lamb=1.5)\n",
        "\n",
        "# fit the model on the training set\n",
        "history = MF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVJc8CB74Mfp",
        "outputId": "a3660728-1553-4452-ed37-0a3769eac986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Matrix Factorization Model ...\n",
            "k=10 \t alpha=0.01 \t lambda=1.5\n",
            "epoch 1/10 - loss : 0.826 - val_loss : 0.827\n",
            "epoch 2/10 - loss : 0.824 - val_loss : 0.825\n",
            "epoch 3/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 4/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 5/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 6/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 7/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 8/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 9/10 - loss : 0.823 - val_loss : 0.825\n",
            "epoch 10/10 - loss : 0.823 - val_loss : 0.825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MF.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usQ_rd6k5Abt",
        "outputId": "85952282-4106-4dc7-cfbf-a9076f8c342f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 0.825\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8250208634455388"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the validation error is 0.825, it means that on average, the model's predictions are off by 0.825 units."
      ],
      "metadata": {
        "id": "AY7czycI5Dil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions"
      ],
      "metadata": {
        "id": "4TX6Odwi5Oex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the latent factors $P$ and $Q$, we can use them to make predictions and recommendations. Let's call the ```predict``` function of the ```Matrix Factorization``` class to make prediction for a given.\n",
        "\n",
        "rating prediction for user 1 on item 1 for which the truth rating $r=5.0$"
      ],
      "metadata": {
        "id": "pphYyt105RKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.userid = uencoder.inverse_transform(ratings.userid.to_list())\n",
        "ratings.itemid = uencoder.inverse_transform(ratings.itemid.to_list())\n",
        "ratings.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XZyMx0175VE5",
        "outputId": "d2d05b00-da3d-4d9e-8491-424e4e22142d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userid  itemid  rating  rating_mean  norm_rating\n",
              "0       1       1       5     4.188679     0.811321\n",
              "1       1      48       5     4.188679     0.811321\n",
              "2       1     145       5     4.188679     0.811321\n",
              "3       1     254       4     4.188679    -0.188679\n",
              "4       1     514       5     4.188679     0.811321"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c08efb5-890f-444a-bfaa-e2d061bbdce7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>itemid</th>\n",
              "      <th>rating</th>\n",
              "      <th>rating_mean</th>\n",
              "      <th>norm_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4.188679</td>\n",
              "      <td>0.811321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>5</td>\n",
              "      <td>4.188679</td>\n",
              "      <td>0.811321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>5</td>\n",
              "      <td>4.188679</td>\n",
              "      <td>0.811321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>254</td>\n",
              "      <td>4</td>\n",
              "      <td>4.188679</td>\n",
              "      <td>-0.188679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>514</td>\n",
              "      <td>5</td>\n",
              "      <td>4.188679</td>\n",
              "      <td>0.811321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c08efb5-890f-444a-bfaa-e2d061bbdce7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1c08efb5-890f-444a-bfaa-e2d061bbdce7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1c08efb5-890f-444a-bfaa-e2d061bbdce7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "4.188679 + MF.predict(userid=1, itemid=1) # add the mean because we have used the normalised ratings for training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGxC3NNG5hBq",
        "outputId": "5c277e9e-52db-4d43-b883-cd1134bf95de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.188679163563357"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, our rating prediction for user 1 on item 1 for which the truth rating $r=5.0$ is 4.2"
      ],
      "metadata": {
        "id": "h4mKX_q-5icb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Non-negative Matrix Factorization for Recommendations"
      ],
      "metadata": {
        "id": "EgDpJ7sq5ycU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jusl like Matrix Factorization (MF) [(Yehuda Koren et al., 2009)](https://ieeexplore.ieee.org/document/5197422), Non-negative Matrix Factorization (NMF in short) factors the rating matrix $R$ in two matrices in such a way that $R = PQ^{\\top}$.\n",
        "\n",
        "**One limitation of Matrix Factorization**\n",
        "\n",
        "$P$ and $Q$ values in MF are non interpretable since their components can take arbitrary (positive and negative) values.\n",
        "\n",
        "**Particulariy of Non-negative Matrix Factorization**\n",
        "\n",
        "NMF [(Lee and Seung, 1999)](http://www.dm.unibo.it/~simoncin/nmfconverge.pdf) allows the reconstruction of $P$ and $Q$ in such a way that $P,Q \\ge 0$. Constraining $P$ and $Q$ values to be taken from $[0,1]$ allows  a probabilistic interpretation\n",
        "\n",
        "- Latent factors represent groups of users who share the same tastes,\n",
        "- The value  $P_{u,l}$  represents the probability that user $u$ belongs to the group $l$ of users and \n",
        "- The value $Q_{l,i}$ represents the probability that users in the group $l$  likes item $i$.\n",
        "\n",
        "**Objective function**\n",
        "\n",
        "With the Euclidian distance, the NMF objective function is defined by\n",
        "\n",
        "\\begin{equation}\n",
        "J = \\frac{1}{2}\\sum_{(u,i) \\in \\kappa}||R_{u,i} - P_uQ_i^{\\top}||^2 + \\lambda_P||P_u||^2 + \\lambda_Q||Q_i||^2\n",
        "\\end{equation}\n",
        "\n",
        "The goal is to minimize the cost function $J$ by optimizing parameters $P$ and $Q$, with $\\lambda_P$ and $\\lambda_Q$ the regularizer parameters."
      ],
      "metadata": {
        "id": "rRaz_bLA52g9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First we prepare the tool that we will use it."
      ],
      "metadata": {
        "id": "rBZ_TsnW_pm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install and import useful packages"
      ],
      "metadata": {
        "id": "lGqCZZPb_qO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ],
      "metadata": {
        "id": "pBuXEsl5_th1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from recsys.preprocessing import mean_ratings\n",
        "from recsys.preprocessing import normalized_ratings\n",
        "from recsys.preprocessing import ids_encoder\n",
        "from recsys.preprocessing import train_test_split\n",
        "from recsys.preprocessing import rating_matrix\n",
        "from recsys.preprocessing import get_examples\n",
        "from recsys.preprocessing import scale_ratings\n",
        "\n",
        "from recsys.datasets import ml1m\n",
        "from recsys.datasets import ml100k\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "6fcHhcp6_wi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load and preprocess rating"
      ],
      "metadata": {
        "id": "9iHhUkOm_3EE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# prepare data\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# convert ratings from dataframe to numpy array\n",
        "np_ratings = ratings.to_numpy()\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=\"rating\")\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "A0NyPAsN_5Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-negative Matrix Factorization Model"
      ],
      "metadata": {
        "id": "D8T9zwGh_-VB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NMF:\n",
        "    \n",
        "    def __init__(self, ratings, m, n, uencoder, iencoder, K=10, lambda_P=0.01, lambda_Q=0.01):\n",
        "        \n",
        "        np.random.seed(32)\n",
        "        \n",
        "        # initialize the latent factor matrices P and Q (of shapes (m,k) and (n,k) respectively) that will be learnt\n",
        "        self.ratings = ratings\n",
        "        self.np_ratings = ratings.to_numpy()\n",
        "        self.K = K\n",
        "        self.P = np.random.rand(m, K)\n",
        "        self.Q = np.random.rand(n, K)\n",
        "        \n",
        "        # hyper parameter initialization\n",
        "        self.lambda_P = lambda_P\n",
        "        self.lambda_Q = lambda_Q\n",
        "\n",
        "        # initialize encoders\n",
        "        self.uencoder = uencoder\n",
        "        self.iencoder = iencoder\n",
        "        \n",
        "        # training history\n",
        "        self.history = {\n",
        "            \"epochs\": [],\n",
        "            \"loss\": [],\n",
        "            \"val_loss\": [],\n",
        "        }\n",
        "    \n",
        "    def print_training_parameters(self):\n",
        "        print('Training NMF ...')\n",
        "        print(f'k={self.K}')\n",
        "        \n",
        "    def mae(self, x_train, y_train):\n",
        "        \"\"\"\n",
        "        returns the Mean Absolute Error\n",
        "        \"\"\"\n",
        "        # number of training examples\n",
        "        m = x_train.shape[0]\n",
        "        error = 0\n",
        "        for pair, r in zip(x_train, y_train):\n",
        "            u, i = pair\n",
        "            error += abs(r - np.dot(self.P[u], self.Q[i]))\n",
        "        return error / m\n",
        "    \n",
        "    def update_rule(self, u, i, error):\n",
        "        I = self.np_ratings[self.np_ratings[:, 0] == u][:, [1, 2]]\n",
        "        U = self.np_ratings[self.np_ratings[:, 1] == i][:, [0, 2]]    \n",
        "                    \n",
        "        num = self.P[u] * np.dot(self.Q[I[:, 0]].T, I[:, 1])\n",
        "        dem = np.dot(self.Q[I[:, 0]].T, np.dot(self.P[u], self.Q[I[:, 0]].T)) + self.lambda_P * len(I) * self.P[u]\n",
        "        self.P[u] = num / dem\n",
        "\n",
        "        num = self.Q[i] * np.dot(self.P[U[:, 0]].T, U[:, 1])\n",
        "        dem = np.dot(self.P[U[:, 0]].T, np.dot(self.P[U[:, 0]], self.Q[i].T)) + self.lambda_Q * len(U) * self.Q[i]\n",
        "        self.Q[i] = num / dem\n",
        "    \n",
        "    @staticmethod\n",
        "    def print_training_progress(epoch, epochs, error, val_error, steps=5):\n",
        "        if epoch == 1 or epoch % steps == 0:\n",
        "            print(f\"epoch {epoch}/{epochs} - loss : {round(error, 3)} - val_loss : {round(val_error, 3)}\")\n",
        "                \n",
        "    def fit(self, x_train, y_train, validation_data, epochs=10):\n",
        "\n",
        "        self.print_training_parameters()\n",
        "        x_test, y_test = validation_data\n",
        "        for epoch in range(1, epochs+1):\n",
        "            for pair, r in zip(x_train, y_train):\n",
        "                u, i = pair\n",
        "                r_hat = np.dot(self.P[u], self.Q[i])\n",
        "                e = abs(r - r_hat)\n",
        "                self.update_rule(u, i, e)                \n",
        "            # training and validation error  after this epochs\n",
        "            error = self.mae(x_train, y_train)\n",
        "            val_error = self.mae(x_test, y_test)\n",
        "            self.update_history(epoch, error, val_error)\n",
        "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
        "        \n",
        "        return self.history\n",
        "    \n",
        "    def update_history(self, epoch, error, val_error):\n",
        "        self.history['epochs'].append(epoch)\n",
        "        self.history['loss'].append(error)\n",
        "        self.history['val_loss'].append(val_error)\n",
        "    \n",
        "    def evaluate(self, x_test, y_test):        \n",
        "        error = self.mae(x_test, y_test)\n",
        "        print(f\"validation error : {round(error,3)}\")\n",
        "        print('MAE : ', error)        \n",
        "        return error\n",
        "      \n",
        "    def predict(self, userid, itemid):\n",
        "        u = self.uencoder.transform([userid])[0]\n",
        "        i = self.iencoder.transform([itemid])[0]\n",
        "        r = np.dot(self.P[u], self.Q[i])\n",
        "        return r\n",
        "\n",
        "    def recommend(self, userid, N=30):\n",
        "        # encode the userid\n",
        "        u = self.uencoder.transform([userid])[0]\n",
        "\n",
        "        # predictions for users userid on all product\n",
        "        predictions = np.dot(self.P[u], self.Q.T)\n",
        "\n",
        "        # get the indices of the top N predictions\n",
        "        top_idx = np.flip(np.argsort(predictions))[:N]\n",
        "\n",
        "        # decode indices to get their corresponding itemids\n",
        "        top_items = self.iencoder.inverse_transform(top_idx)\n",
        "\n",
        "        # take corresponding predictions for top N indices\n",
        "        preds = predictions[top_idx]\n",
        "\n",
        "        return top_items, preds\n"
      ],
      "metadata": {
        "id": "N791ILH4ABlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the NMF model with ML-100K dataset"
      ],
      "metadata": {
        "id": "au0PyW3_AFYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model parameters :\n",
        "\n",
        "- $k = 10$ : (number of factors)\n",
        "- $\\lambda_P = 0.6$\n",
        "- $\\lambda_Q = 0.6$\n",
        "- epochs = 10\n",
        "\n",
        "Note that it may take some time to complete the training on 10 epochs (around 7 minutes)."
      ],
      "metadata": {
        "id": "UuKqvJHUALOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = ratings['userid'].nunique()   # total number of users\n",
        "n = ratings['itemid'].nunique()   # total number of items\n",
        "\n",
        "# create and train the model\n",
        "nmf = NMF(ratings, m, n, uencoder, iencoder, K=10, lambda_P=0.6, lambda_Q=0.6)\n",
        "history = nmf.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gfLvF-KAL7B",
        "outputId": "4a2f94e6-5df9-4104-89f2-9c80f6593407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training NMF ...\n",
            "k=10\n",
            "epoch 1/10 - loss : 0.916 - val_loss : 0.917\n",
            "epoch 2/10 - loss : 0.915 - val_loss : 0.917\n",
            "epoch 3/10 - loss : 0.915 - val_loss : 0.917\n",
            "epoch 4/10 - loss : 0.915 - val_loss : 0.917\n",
            "epoch 5/10 - loss : 0.915 - val_loss : 0.917\n",
            "epoch 6/10 - loss : 0.915 - val_loss : 0.917\n",
            "epoch 7/10 - loss : 0.915 - val_loss : 0.917\n",
            "epoch 8/10 - loss : 0.915 - val_loss : 0.917\n",
            "epoch 9/10 - loss : 0.915 - val_loss : 0.917\n",
            "epoch 10/10 - loss : 0.915 - val_loss : 0.917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nmf.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b38RQFVgC0ZM",
        "outputId": "18a1efed-220e-4e8a-d6de-cac1c01f449f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 0.917\n",
            "MAE :  0.9165041343019539\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9165041343019539"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the validation error is 0.917, it means that on average, the model's predictions are off by 0.917 units."
      ],
      "metadata": {
        "id": "vUiqSqh6C3hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of NMF with Scikit-suprise"
      ],
      "metadata": {
        "id": "3Kx1eHF4C-m8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the [scikt-suprise](https://surprise.readthedocs.io/en/stable/) package to train the NMF model. It  is an easy-to-use Python scikit for recommender systems.\n",
        "\n",
        "1. Import the NMF class from the suprise scikit.\n",
        "2. Load the data with the built-in function\n",
        "3. Instanciate NMF with ```k=10``` (```n_factors```) and we use 10 epochs (```n_epochs```)\n",
        "4. Evaluate the model using cross-validation with 5 folds."
      ],
      "metadata": {
        "id": "-i85Ct6FDAVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v12IJCHnEDYM",
        "outputId": "24a961a6-ad78-483e-dd2b-c64678ec0872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[K     |████████████████████████████████| 771 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-surprise) (1.7.3)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp38-cp38-linux_x86_64.whl size=2626504 sha256=230ddf5c84c5a5c3d4b7d4f9d1c141b5d50659a9e6ec11c914f7b185b105134f\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/db/86/2c18183a80ba05da35bf0fb7417aac5cddbd93bcb1b92fd3ea\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import NMF\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Load the movielens-100k dataset (download it if needed).\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# Use the NMF algorithm.\n",
        "nmf = NMF(n_factors=10, n_epochs=10)\n",
        "\n",
        "# Run 5-fold cross-validation and print results.\n",
        "history = cross_validate(nmf, data, measures=['MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1vtvVlxDC48",
        "outputId": "955a436a-81a8-475b-e38d-fb5e4b97fe8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating MAE of algorithm NMF on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.9584  0.9640  0.9456  0.9566  0.9481  0.9545  0.0068  \n",
            "Fit time          0.50    0.48    0.49    0.49    0.50    0.49    0.01    \n",
            "Test time         0.34    0.24    0.23    0.15    0.23    0.24    0.06    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As result, the mean MAE on the test set in Folder 5 is **MAE = 0.9481** which is equivalent to the result we have obtained on *ml-100k* with our own implementation **mae = 0.9165**"
      ],
      "metadata": {
        "id": "yFPItUj2Egt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **ML-1M**\n"
      ],
      "metadata": {
        "id": "g4g5rwc0Ejr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset.load_builtin('ml-1m')\n",
        "nmf = NMF(n_factors=10, n_epochs=10)\n",
        "history = cross_validate(nmf, data, measures=['MAE'], cv=5, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7765VWsE7Uc",
        "outputId": "99a04363-98b6-493e-d1d0-676517e65d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ml-1m could not be found. Do you want to download it? [Y/n] y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-1m.zip...\n",
            "Done! Dataset ml-1m has been saved to /root/.surprise_data/ml-1m\n",
            "Evaluating MAE of algorithm NMF on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "MAE (testset)     0.9553  0.9546  0.9598  0.9582  0.9546  0.9565  0.0021  \n",
            "Fit time          3.88    4.13    4.40    4.26    4.36    4.21    0.19    \n",
            "Test time         2.61    2.39    2.84    2.13    2.73    2.54    0.25    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean MAE on a 5-fold cross-validation is **MAE = 0.9546**\n"
      ],
      "metadata": {
        "id": "LzNylOdAFc1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 4: Explainable Matrix Factorization (EMF)"
      ],
      "metadata": {
        "id": "ID2yrxbPF-xZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to quantify explainability ?\n",
        "\n",
        "- Use the rating distribution within the active user’s neighborhood. \n",
        "- If many neighbors have rated the recommended item, then this can provide a basis upon which to explain the recommendations, using neighborhood style explanation mechanisms"
      ],
      "metadata": {
        "id": "yvtsIjVHGQJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By including explainability weight in the training algorithm, the new objective function, to be minimized over the set of known ratings, has been formulated by [(Abdollahi and Nasraoui, 2016)](https://www.researchgate.net/publication/301616080_Explainable_Matrix_Factorization_for_Collaborative_Filtering) as:\n",
        "\n",
        "\\begin{equation}\n",
        " J = \\sum_{(u,i)\\in \\kappa} (R_{ui} - \\hat{R}_{ui})^2 +\\frac{\\beta}{2}(||P_u||^2 + ||Q_i||^2) + \\frac{\\lambda}{2}(P_u-Q_i)^2W_{ui},\n",
        "\\end{equation}\n",
        "\n",
        "here, $\\frac{\\beta}{2}(||P_u||^2 + ||Q_i||^2)$ is the $L_2$ regularization term weighted by the coefficient $\\beta$, and $\\lambda$ is an explainability regularization coefficient that controls the smoothness of the new representation and tradeoff between explainability and accuracy. The idea here is that if item $i$ is explainable for user $u$, then their representations in the latent space, $Q_i$ and $P_u$, should be close to each other. Stochastic Gradient descent can be used to optimize the objectve function.\n",
        "\n",
        "\\begin{equation}\n",
        "P_u \\leftarrow P_u + \\alpha\\left(2(R_{u,i}-P_uQ_i^{\\top})Q_i - \\beta P_u - \\lambda(P_u-Q_i)W_{ui}\\right)\n",
        "\\end{equation}\n",
        "\\begin{equation}\n",
        "Q_i \\leftarrow Q_i + \\alpha\\left(2(R_{u,i}-P_uQ_i^{\\top})P_u - \\beta Q_i + \\lambda(P_u-Q_i)W_{ui}\\right)\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "kzSdkNWRHEEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First we prepare the tool that we will use it."
      ],
      "metadata": {
        "id": "KrElkiReHLJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not (os.path.exists(\"recsys.zip\") or os.path.exists(\"recsys\")):\n",
        "    !wget https://github.com/nzhinusoftcm/review-on-collaborative-filtering/raw/master/recsys.zip    \n",
        "    !unzip recsys.zip"
      ],
      "metadata": {
        "id": "DJHBPkd6HVN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from recsys.memories.UserToUser import UserToUser\n",
        "\n",
        "from recsys.preprocessing import mean_ratings\n",
        "from recsys.preprocessing import normalized_ratings\n",
        "from recsys.preprocessing import ids_encoder\n",
        "from recsys.preprocessing import train_test_split\n",
        "from recsys.preprocessing import rating_matrix\n",
        "from recsys.preprocessing import get_examples\n",
        "\n",
        "from recsys.datasets import ml100k, ml1m\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import os"
      ],
      "metadata": {
        "id": "7lP6T864HYF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Explainable Scores"
      ],
      "metadata": {
        "id": "rFdkDP-OHdgl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explainable score are computed using neighborhood based similarities. Here, we are using the user based algorithme to compute similarities."
      ],
      "metadata": {
        "id": "UqbTXsVqHeuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explainable_score(user2user, users, items, theta=0):\n",
        "    \n",
        "    def _progress(count):\n",
        "        sys.stdout.write('\\rCompute Explainable score. Progress status : %.1f%%'%(float(count/len(users))*100.0))\n",
        "        sys.stdout.flush()\n",
        "    # initialize explainable score to zeros\n",
        "    W = np.zeros((len(users), len(items)))\n",
        "\n",
        "    for count, u in enumerate(users):            \n",
        "        candidate_items = user2user.find_user_candidate_items(u)        \n",
        "        for i in candidate_items:                \n",
        "            user_who_rated_i, similar_user_who_rated_i = \\\n",
        "                user2user.similar_users_who_rated_this_item(u, i)\n",
        "            if user_who_rated_i.shape[0] == 0:\n",
        "                w = 0.0\n",
        "            else:\n",
        "                w = similar_user_who_rated_i.shape[0] / user_who_rated_i.shape[0]\n",
        "            W[u,i] =  w  if w > theta else 0.0\n",
        "        _progress(count)\n",
        "    return W"
      ],
      "metadata": {
        "id": "IHMMaVqNHhn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explainable Matrix Factorization Model"
      ],
      "metadata": {
        "id": "NPN63ierHqxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExplainableMatrixFactorization:\n",
        "    \n",
        "    def __init__(self, m, n, W, alpha=0.001, beta=0.01, lamb=0.1, k=10):\n",
        "        \"\"\"\n",
        "            - R : Rating matrix of shape (m,n) \n",
        "            - W : Explainability Weights of shape (m,n)\n",
        "            - k : number of latent factors\n",
        "            - beta : L2 regularization parameter\n",
        "            - lamb : explainability regularization coefficient\n",
        "            - theta : threshold above which an item is explainable for a user\n",
        "        \"\"\"\n",
        "        self.W = W\n",
        "        self.m = m\n",
        "        self.n = n\n",
        "        \n",
        "        np.random.seed(64)\n",
        "        \n",
        "        # initialize the latent factor matrices P and Q (of shapes (m,k) and (n,k) respectively) that will be learnt\n",
        "        self.k = k\n",
        "        self.P = np.random.normal(size=(self.m,k))\n",
        "        self.Q = np.random.normal(size=(self.n,k))\n",
        "        \n",
        "        # hyperparameter initialization\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.lamb = lamb\n",
        "        \n",
        "        # training history\n",
        "        self.history = {\n",
        "            \"epochs\":[],\n",
        "            \"loss\":[],\n",
        "            \"val_loss\":[],\n",
        "        }\n",
        "        \n",
        "    def print_training_parameters(self):\n",
        "        print('Training EMF')\n",
        "        print(f'k={self.k} \\t alpha={self.alpha} \\t beta={self.beta} \\t lambda={self.lamb}')\n",
        "        \n",
        "    def update_rule(self, u, i, error):\n",
        "        self.P[u] = self.P[u] + \\\n",
        "            self.alpha*(2 * error*self.Q[i] - self.beta*self.P[u] - self.lamb*(self.P[u] - self.Q[i]) * self.W[u,i])\n",
        "        \n",
        "        self.Q[i] = self.Q[i] + \\\n",
        "            self.alpha*(2 * error*self.P[u] - self.beta*self.Q[i] + self.lamb*(self.P[u] - self.Q[i]) * self.W[u,i])\n",
        "        \n",
        "    def mae(self,  x_train, y_train):\n",
        "        \"\"\"\n",
        "        returns the Mean Absolute Error\n",
        "        \"\"\"\n",
        "        # number of training exemples\n",
        "        M = x_train.shape[0]\n",
        "        error = 0\n",
        "        for pair, r in zip(x_train, y_train):\n",
        "            u, i = pair\n",
        "            error += np.absolute(r - np.dot(self.P[u], self.Q[i]))\n",
        "        return error/M\n",
        "    \n",
        "    def print_training_progress(self, epoch, epochs, error, val_error, steps=5):\n",
        "        if epoch == 1 or epoch % steps == 0 :\n",
        "                print(f\"epoch {epoch}/{epochs} - loss : {round(error,3)} - val_loss : {round(val_error,3)}\")\n",
        "                \n",
        "    def learning_rate_schedule(self, epoch, target_epochs = 20):\n",
        "        if (epoch >= target_epochs) and (epoch % target_epochs == 0):\n",
        "                factor = epoch // target_epochs\n",
        "                self.alpha = self.alpha * (1 / (factor * 20))\n",
        "                print(\"\\nLearning Rate : {}\\n\".format(self.alpha))\n",
        "        \n",
        "    def fit(self, x_train, y_train, validation_data, epochs=10):\n",
        "        \"\"\"\n",
        "        Train latent factors P and Q according to the training set\n",
        "        \n",
        "        :param\n",
        "            - x_train : training pairs (u,i) for which rating r_ui is known\n",
        "            - y_train : set of ratings r_ui for all training pairs (u,i)\n",
        "            - validation_data : tuple (x_test, y_test)\n",
        "            - epochs : number of time to loop over the entire training set. \n",
        "            10 epochs by default\n",
        "            \n",
        "        Note that u and i are encoded values of userid and itemid\n",
        "        \"\"\"\n",
        "        self.print_training_parameters()\n",
        "        \n",
        "        # get validation data\n",
        "        x_test, y_test = validation_data\n",
        "        \n",
        "        for epoch in range(1, epochs+1):\n",
        "            for pair, r in zip(x_train, y_train):                \n",
        "                u,i = pair                \n",
        "                r_hat = np.dot(self.P[u], self.Q[i])                \n",
        "                e = r - r_hat\n",
        "                self.update_rule(u, i, error=e)\n",
        "                \n",
        "            # training and validation error  after this epochs\n",
        "            error = self.mae(x_train, y_train)\n",
        "            val_error = self.mae(x_test, y_test)\n",
        "            self.update_history(epoch, error, val_error)            \n",
        "            self.print_training_progress(epoch, epochs, error, val_error, steps=1)\n",
        "        \n",
        "        return self.history\n",
        "    \n",
        "    def update_history(self, epoch, error, val_error):\n",
        "        self.history['epochs'].append(epoch)\n",
        "        self.history['loss'].append(error)\n",
        "        self.history['val_loss'].append(val_error)\n",
        "    \n",
        "    def evaluate(self, x_test, y_test):\n",
        "        \"\"\"\n",
        "        compute the global error on the test set\n",
        "        \n",
        "        :param\n",
        "            - x_test : test pairs (u,i) for which rating r_ui is known\n",
        "            - y_test : set of ratings r_ui for all test pairs (u,i)\n",
        "        \"\"\"\n",
        "        error = self.mae(x_test, y_test)\n",
        "        print(f\"validation error : {round(error,3)}\")\n",
        "      \n",
        "    def predict(self, userid, itemid):\n",
        "        \"\"\"\n",
        "        Make rating prediction for a user on an item\n",
        "\n",
        "        :param\n",
        "        - userid\n",
        "        - itemid\n",
        "\n",
        "        :return\n",
        "        - r : predicted rating\n",
        "        \"\"\"\n",
        "        # encode user and item ids to be able to access their latent factors in\n",
        "        # matrices P and Q\n",
        "        u = uencoder.transform([userid])[0]\n",
        "        i = iencoder.transform([itemid])[0]\n",
        "\n",
        "        # rating prediction using encoded ids. Dot product between P_u and Q_i\n",
        "        r = np.dot(self.P[u], self.Q[i])\n",
        "\n",
        "        return r\n",
        "\n",
        "    def recommend(self, userid, N=30):\n",
        "        \"\"\"\n",
        "        make to N recommendations for a given user\n",
        "\n",
        "        :return \n",
        "        - (top_items,preds) : top N items with the highest predictions \n",
        "        \"\"\"\n",
        "        # encode the userid\n",
        "        u = uencoder.transform([userid])[0]\n",
        "\n",
        "        # predictions for this user on all product\n",
        "        predictions = np.dot(self.P[u], self.Q.T)\n",
        "\n",
        "        # get the indices of the top N predictions\n",
        "        top_idx = np.flip(np.argsort(predictions))[:N]\n",
        "\n",
        "        # decode indices to get their corresponding itemids\n",
        "        top_items = iencoder.inverse_transform(top_idx)\n",
        "\n",
        "        # take corresponding predictions for top N indices\n",
        "        preds = predictions[top_idx]\n",
        "\n",
        "        return top_items, preds"
      ],
      "metadata": {
        "id": "llxSYTO-HuIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "Q3otkYQkH1CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "metadata": {
        "id": "cimPSi-jH6oY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MovieLens 100K"
      ],
      "metadata": {
        "id": "lCHThLuqH92Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Evaluation on raw data**"
      ],
      "metadata": {
        "id": "2sUWeexFIAoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "9tkc3CRiIELC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the user to user model for similarity measure\n",
        "usertouser = UserToUser(ratings, movies)\n",
        "\n",
        "# compute explainable score\n",
        "W = explainable_score(usertouser, users, items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpA0Y_1IHPo",
        "outputId": "12a3d259-ad28-41cc-b5af-b0f47b65c0bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "Compute Explainable score. Progress status : 99.9%"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.01, beta=0.4, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA3b5T6VISDJ",
        "outputId": "ee4dfa86-8790-43e6-cf18-54e2190258da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.01 \t beta=0.4 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.922 - val_loss : 1.036\n",
            "epoch 2/10 - loss : 0.79 - val_loss : 0.873\n",
            "epoch 3/10 - loss : 0.766 - val_loss : 0.837\n",
            "epoch 4/10 - loss : 0.757 - val_loss : 0.822\n",
            "epoch 5/10 - loss : 0.753 - val_loss : 0.814\n",
            "epoch 6/10 - loss : 0.751 - val_loss : 0.808\n",
            "epoch 7/10 - loss : 0.749 - val_loss : 0.805\n",
            "epoch 8/10 - loss : 0.748 - val_loss : 0.802\n",
            "epoch 9/10 - loss : 0.746 - val_loss : 0.799\n",
            "epoch 10/10 - loss : 0.745 - val_loss : 0.797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMF.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYPZILImIfVG",
        "outputId": "8b44faa8-abd5-4e9a-bb6b-81483e95b0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation error : 0.797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the validation error is 0.797, it means that on average, the model's predictions are off by 0.797 units."
      ],
      "metadata": {
        "id": "oSz4DUwrIhx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Evaluation on normalized data**"
      ],
      "metadata": {
        "id": "HPCDyPfpIsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml100k.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "2xsAtgk1I1ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.022, beta=0.65, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB-5nGl7I49N",
        "outputId": "13bc398c-9a8f-43fe-be12-5e1a0f27aaae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.022 \t beta=0.65 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.809 - val_loss : 0.842\n",
            "epoch 2/10 - loss : 0.809 - val_loss : 0.829\n",
            "epoch 3/10 - loss : 0.807 - val_loss : 0.821\n",
            "epoch 4/10 - loss : 0.799 - val_loss : 0.811\n",
            "epoch 5/10 - loss : 0.789 - val_loss : 0.8\n",
            "epoch 6/10 - loss : 0.782 - val_loss : 0.793\n",
            "epoch 7/10 - loss : 0.778 - val_loss : 0.789\n",
            "epoch 8/10 - loss : 0.776 - val_loss : 0.786\n",
            "epoch 9/10 - loss : 0.774 - val_loss : 0.784\n",
            "epoch 10/10 - loss : 0.773 - val_loss : 0.783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MovieLens 1M"
      ],
      "metadata": {
        "id": "B_K4GPtDJJgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Evaluation on raw data**"
      ],
      "metadata": {
        "id": "mo_-Dl15JLjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "users = sorted(ratings.userid.unique())\n",
        "items = sorted(ratings.itemid.unique())\n",
        "\n",
        "m = len(users)\n",
        "n = len(items)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "OZmLeSvFJPMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the user to user model for similarity measure\n",
        "usertouser = UserToUser(ratings, movies)\n",
        "\n",
        "# compute explainable score\n",
        "W = explainable_score(usertouser, users, items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY8rdoYvJUFY",
        "outputId": "62df36f7-66ac-4606-b12e-1933aec2befc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalize users ratings ...\n",
            "Initialize the similarity model ...\n",
            "Compute nearest neighbors ...\n",
            "User to user recommendation model created with success ...\n",
            "Compute Explainable score. Progress status : 100.0%"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.01, beta=0.4, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGy9SYi3OTVZ",
        "outputId": "97104f88-2ebb-4ea5-e6c1-d3c742864af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.01 \t beta=0.4 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.782 - val_loss : 0.807\n",
            "epoch 2/10 - loss : 0.762 - val_loss : 0.781\n",
            "epoch 3/10 - loss : 0.76 - val_loss : 0.775\n",
            "epoch 4/10 - loss : 0.758 - val_loss : 0.771\n",
            "epoch 5/10 - loss : 0.757 - val_loss : 0.769\n",
            "epoch 6/10 - loss : 0.756 - val_loss : 0.767\n",
            "epoch 7/10 - loss : 0.754 - val_loss : 0.764\n",
            "epoch 8/10 - loss : 0.752 - val_loss : 0.762\n",
            "epoch 9/10 - loss : 0.751 - val_loss : 0.761\n",
            "epoch 10/10 - loss : 0.75 - val_loss : 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Evaluation on normalized data**"
      ],
      "metadata": {
        "id": "tug-GUqDP3RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "ratings, movies = ml1m.load()\n",
        "\n",
        "# encode users and items ids\n",
        "ratings, uencoder, iencoder = ids_encoder(ratings)\n",
        "\n",
        "# normalize ratings by substracting means\n",
        "normalized_column_name = \"norm_rating\"\n",
        "ratings = normalized_ratings(ratings, norm_column=normalized_column_name)\n",
        "\n",
        "# get examples as tuples of userids and itemids and labels from normalize ratings\n",
        "raw_examples, raw_labels = get_examples(ratings, labels_column=normalized_column_name)\n",
        "\n",
        "# train test split\n",
        "(x_train, x_test), (y_train, y_test) = train_test_split(examples=raw_examples, labels=raw_labels)"
      ],
      "metadata": {
        "id": "2-t5jYDQP7Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the model\n",
        "EMF = ExplainableMatrixFactorization(m, n, W, alpha=0.023, beta=0.59, lamb=0.01, k=10)\n",
        "\n",
        "history = EMF.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH4QXDRMQS8r",
        "outputId": "d107aa2d-5d4d-42bc-8b26-2669c9bbe385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training EMF\n",
            "k=10 \t alpha=0.023 \t beta=0.59 \t lambda=0.01\n",
            "epoch 1/10 - loss : 0.805 - val_loss : 0.814\n",
            "epoch 2/10 - loss : 0.764 - val_loss : 0.77\n",
            "epoch 3/10 - loss : 0.756 - val_loss : 0.762\n",
            "epoch 4/10 - loss : 0.755 - val_loss : 0.759\n",
            "epoch 5/10 - loss : 0.754 - val_loss : 0.759\n",
            "epoch 6/10 - loss : 0.754 - val_loss : 0.758\n",
            "epoch 7/10 - loss : 0.754 - val_loss : 0.758\n",
            "epoch 8/10 - loss : 0.753 - val_loss : 0.758\n",
            "epoch 9/10 - loss : 0.753 - val_loss : 0.758\n",
            "epoch 10/10 - loss : 0.753 - val_loss : 0.758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ratings prediction"
      ],
      "metadata": {
        "id": "sGe2QMD6Rlmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get list of top N items with their corresponding predicted ratings\n",
        "userid = 42\n",
        "recommended_items, predictions = EMF.recommend(userid=userid)\n",
        "\n",
        "# find corresponding movie titles\n",
        "top_N = list(zip(recommended_items,predictions))\n",
        "top_N = pd.DataFrame(top_N, columns=['itemid','predictions'])\n",
        "top_N.predictions = top_N.predictions + ratings.loc[ratings.userid==userid].rating_mean.values[0]\n",
        "List = pd.merge(top_N, movies, on='itemid', how='inner')\n",
        "\n",
        "# show the list\n",
        "List"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "Mnvm5nhZRsWh",
        "outputId": "380ae133-4331-4773-d90f-0ce67e7a8fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    itemid  predictions                                              title  \\\n",
              "0     3460     4.364036               Hillbillys in a Haunted House (1967)   \n",
              "1      701     4.324177                                       Daens (1992)   \n",
              "2     3057     4.307404                            Where's Marlowe? (1999)   \n",
              "3     2214     4.304979                            Number Seventeen (1932)   \n",
              "4     1145     4.299559                                  Snowriders (1996)   \n",
              "5     2258     4.292125                              Master Ninja I (1984)   \n",
              "6     3353     4.281912                         Closer You Get, The (2000)   \n",
              "7      868     4.278937                          Death in Brunswick (1991)   \n",
              "8      826     4.269901                                   Diebinnen (1995)   \n",
              "9     3305     4.266769                                   Bluebeard (1944)   \n",
              "10    2619     4.265997                                     Mascara (1999)   \n",
              "11     763     4.264092  Last of the High Kings, The (a.k.a. Summer Fli...   \n",
              "12    1852     4.262517                              Love Walked In (1998)   \n",
              "13     642     4.260353                                       Roula (1995)   \n",
              "14     682     4.258829         Tigrero: A Film That Was Never Made (1994)   \n",
              "15     792     4.253339                     Hungarian Fairy Tale, A (1987)   \n",
              "16    1316     4.252915                                        Anna (1996)   \n",
              "17    3228     4.245526                              Wirey Spindell (1999)   \n",
              "18     853     4.240745                                       Dingo (1992)   \n",
              "19    3172     4.238188                            Ulysses (Ulisse) (1954)   \n",
              "20    2254     4.238008                                     Choices (1981)   \n",
              "21    2503     4.234547                            Apple, The (Sib) (1998)   \n",
              "22    2905     4.224974                                     Sanjuro (1962)   \n",
              "23     744     4.224278                         Brothers in Trouble (1995)   \n",
              "24     757     4.224226                               Ashes of Time (1994)   \n",
              "25     858     4.223665                              Godfather, The (1972)   \n",
              "26     789     4.220788      I, Worst of All (Yo, la peor de todas) (1990)   \n",
              "27    3748     4.216508                                  Match, The (1999)   \n",
              "28     790     4.216455                     An Unforgettable Summer (1994)   \n",
              "29     745     4.215986                              Close Shave, A (1995)   \n",
              "\n",
              "                       genres  \n",
              "0                      Comedy  \n",
              "1                       Drama  \n",
              "2                      Comedy  \n",
              "3                    Thriller  \n",
              "4                 Documentary  \n",
              "5                      Action  \n",
              "6              Comedy|Romance  \n",
              "7                      Comedy  \n",
              "8                       Drama  \n",
              "9            Film-Noir|Horror  \n",
              "10                      Drama  \n",
              "11                      Drama  \n",
              "12             Drama|Thriller  \n",
              "13                      Drama  \n",
              "14          Documentary|Drama  \n",
              "15                    Fantasy  \n",
              "16                      Drama  \n",
              "17                     Comedy  \n",
              "18                      Drama  \n",
              "19                  Adventure  \n",
              "20                      Drama  \n",
              "21                      Drama  \n",
              "22           Action|Adventure  \n",
              "23                      Drama  \n",
              "24                      Drama  \n",
              "25         Action|Crime|Drama  \n",
              "26                      Drama  \n",
              "27             Comedy|Romance  \n",
              "28                      Drama  \n",
              "29  Animation|Comedy|Thriller  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-099a39ba-439b-4317-b96c-1f12872572e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itemid</th>\n",
              "      <th>predictions</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3460</td>\n",
              "      <td>4.364036</td>\n",
              "      <td>Hillbillys in a Haunted House (1967)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>701</td>\n",
              "      <td>4.324177</td>\n",
              "      <td>Daens (1992)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3057</td>\n",
              "      <td>4.307404</td>\n",
              "      <td>Where's Marlowe? (1999)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2214</td>\n",
              "      <td>4.304979</td>\n",
              "      <td>Number Seventeen (1932)</td>\n",
              "      <td>Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145</td>\n",
              "      <td>4.299559</td>\n",
              "      <td>Snowriders (1996)</td>\n",
              "      <td>Documentary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2258</td>\n",
              "      <td>4.292125</td>\n",
              "      <td>Master Ninja I (1984)</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3353</td>\n",
              "      <td>4.281912</td>\n",
              "      <td>Closer You Get, The (2000)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>868</td>\n",
              "      <td>4.278937</td>\n",
              "      <td>Death in Brunswick (1991)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>826</td>\n",
              "      <td>4.269901</td>\n",
              "      <td>Diebinnen (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3305</td>\n",
              "      <td>4.266769</td>\n",
              "      <td>Bluebeard (1944)</td>\n",
              "      <td>Film-Noir|Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2619</td>\n",
              "      <td>4.265997</td>\n",
              "      <td>Mascara (1999)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>763</td>\n",
              "      <td>4.264092</td>\n",
              "      <td>Last of the High Kings, The (a.k.a. Summer Fli...</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1852</td>\n",
              "      <td>4.262517</td>\n",
              "      <td>Love Walked In (1998)</td>\n",
              "      <td>Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>642</td>\n",
              "      <td>4.260353</td>\n",
              "      <td>Roula (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>682</td>\n",
              "      <td>4.258829</td>\n",
              "      <td>Tigrero: A Film That Was Never Made (1994)</td>\n",
              "      <td>Documentary|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>792</td>\n",
              "      <td>4.253339</td>\n",
              "      <td>Hungarian Fairy Tale, A (1987)</td>\n",
              "      <td>Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1316</td>\n",
              "      <td>4.252915</td>\n",
              "      <td>Anna (1996)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3228</td>\n",
              "      <td>4.245526</td>\n",
              "      <td>Wirey Spindell (1999)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>853</td>\n",
              "      <td>4.240745</td>\n",
              "      <td>Dingo (1992)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3172</td>\n",
              "      <td>4.238188</td>\n",
              "      <td>Ulysses (Ulisse) (1954)</td>\n",
              "      <td>Adventure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2254</td>\n",
              "      <td>4.238008</td>\n",
              "      <td>Choices (1981)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2503</td>\n",
              "      <td>4.234547</td>\n",
              "      <td>Apple, The (Sib) (1998)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2905</td>\n",
              "      <td>4.224974</td>\n",
              "      <td>Sanjuro (1962)</td>\n",
              "      <td>Action|Adventure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>744</td>\n",
              "      <td>4.224278</td>\n",
              "      <td>Brothers in Trouble (1995)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>757</td>\n",
              "      <td>4.224226</td>\n",
              "      <td>Ashes of Time (1994)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>858</td>\n",
              "      <td>4.223665</td>\n",
              "      <td>Godfather, The (1972)</td>\n",
              "      <td>Action|Crime|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>789</td>\n",
              "      <td>4.220788</td>\n",
              "      <td>I, Worst of All (Yo, la peor de todas) (1990)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3748</td>\n",
              "      <td>4.216508</td>\n",
              "      <td>Match, The (1999)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>790</td>\n",
              "      <td>4.216455</td>\n",
              "      <td>An Unforgettable Summer (1994)</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>745</td>\n",
              "      <td>4.215986</td>\n",
              "      <td>Close Shave, A (1995)</td>\n",
              "      <td>Animation|Comedy|Thriller</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-099a39ba-439b-4317-b96c-1f12872572e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-099a39ba-439b-4317-b96c-1f12872572e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-099a39ba-439b-4317-b96c-1f12872572e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: The recommendation list may content items already purchased by the user. This is just an illustration of how to implement matrix factorization recommender system."
      ],
      "metadata": {
        "id": "nt7U9WyURvPJ"
      }
    }
  ]
}